# E2E è´Ÿè½½å‡è¡¡å™¨æµ‹è¯•è®¡åˆ’

**åˆ›å»ºæ—¶é—´**: 2025-11-27  
**åœºæ™¯**: Nginxè´Ÿè½½å‡è¡¡ + å¤šServerå®ä¾‹ + å…±äº«Redis  
**æ ¸å¿ƒæŒ‘æˆ˜**: å‘½ä»¤é€šé“å’Œæ˜ å°„è¿æ¥å¯èƒ½è½åœ¨ä¸åŒServerä¸Š  

---

## ğŸ¯ æµ‹è¯•åœºæ™¯æ¦‚è¿°

### æ¶æ„æ‹“æ‰‘

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   Nginx LB   â”‚  (è´Ÿè½½å‡è¡¡å™¨)
                         â”‚ :7000 (TCP)  â”‚
                         â”‚ :7001 (WS)   â”‚
                         â”‚ :7002 (UDP)  â”‚
                         â”‚ :7003 (QUIC) â”‚
                         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚               â”‚               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ Server-1     â”‚ â”‚ Server-2   â”‚ â”‚ Server-3   â”‚
        â”‚ (node-1)     â”‚ â”‚ (node-2)   â”‚ â”‚ (node-3)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚               â”‚               â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚    Redis     â”‚  (å…±äº«å­˜å‚¨+MQ)
                        â”‚   :6379      â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â–²
                               â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  RabbitMQ    â”‚  (å¯é€‰ï¼Œé«˜çº§MQ)
                        â”‚   :5672      â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

å®¢æˆ·ç«¯A (æ§åˆ¶è¿æ¥) â”€â”€â†’ Nginx â”€â”€â†’ å¯èƒ½åˆ° Server-1
å®¢æˆ·ç«¯A (éš§é“1)    â”€â”€â†’ Nginx â”€â”€â†’ å¯èƒ½åˆ° Server-2
å®¢æˆ·ç«¯A (éš§é“2)    â”€â”€â†’ Nginx â”€â”€â†’ å¯èƒ½åˆ° Server-3
å®¢æˆ·ç«¯B (æ§åˆ¶è¿æ¥) â”€â”€â†’ Nginx â”€â”€â†’ å¯èƒ½åˆ° Server-2
å®¢æˆ·ç«¯B (éš§é“1)    â”€â”€â†’ Nginx â”€â”€â†’ å¯èƒ½åˆ° Server-1
```

### æ ¸å¿ƒæŒ‘æˆ˜

1. **æ§åˆ¶è¿æ¥å’Œéš§é“è¿æ¥åˆ†ç¦»**
   - å®¢æˆ·ç«¯Açš„æ§åˆ¶è¿æ¥åœ¨Server-1
   - å®¢æˆ·ç«¯Açš„éš§é“è¿æ¥å¯èƒ½åœ¨Server-2
   - å®¢æˆ·ç«¯Bçš„æ§åˆ¶è¿æ¥åœ¨Server-3
   - Aâ†’Bçš„éš§é“æ¡¥æ¥éœ€è¦è·¨Serveré€šä¿¡

2. **ä¼šè¯çŠ¶æ€å…±äº«**
   - Sessionä¿¡æ¯å­˜å‚¨åœ¨Redis
   - éœ€è¦æ‰€æœ‰Serverèƒ½æŸ¥è¯¢åˆ°æ‰€æœ‰å®¢æˆ·ç«¯
   - éœ€è¦åˆ†å¸ƒå¼é”ä¿è¯ä¸€è‡´æ€§

3. **æ¶ˆæ¯è·¯ç”±**
   - é…ç½®æ¨é€éœ€è¦é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—
   - TunnelOpenè¯·æ±‚éœ€è¦è·¨Serverè·¯ç”±
   - å¿ƒè·³æ£€æµ‹éœ€è¦å…¨å±€åè°ƒ

4. **è´Ÿè½½å‡è¡¡ç­–ç•¥**
   - Round-robinï¼ˆè½®è¯¢ï¼‰
   - Least connectionsï¼ˆæœ€å°‘è¿æ¥ï¼‰
   - IP Hashï¼ˆæºIPå“ˆå¸Œï¼‰
   - ä¸åŒç­–ç•¥å¯¹æµ‹è¯•çš„å½±å“

---

## ğŸ“‹ æµ‹è¯•è®¡åˆ’

### é˜¶æ®µ6.1: è´Ÿè½½å‡è¡¡åŸºç¡€æµ‹è¯• (1å¤©)

#### æµ‹è¯•ç›®æ ‡
éªŒè¯åŸºæœ¬çš„è´Ÿè½½å‡è¡¡åŠŸèƒ½å’Œè·¨Serveré€šä¿¡

#### Docker Compose é…ç½®

**æ–‡ä»¶**: `tests/e2e/docker-compose.load-balancer.yml`

```yaml
version: '3.8'

services:
  # Redis (å…±äº«å­˜å‚¨å’Œæ¶ˆæ¯é˜Ÿåˆ—)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    networks:
      - tunnox-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  # RabbitMQ (å¯é€‰ï¼Œé«˜çº§æ¶ˆæ¯é˜Ÿåˆ—)
  rabbitmq:
    image: rabbitmq:3-management-alpine
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: tunnox
      RABBITMQ_DEFAULT_PASS: tunnox123
    networks:
      - tunnox-net
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Tunnox Server å®ä¾‹1
  tunnox-server-1:
    build:
      context: ../..
      dockerfile: Dockerfile.server
    environment:
      - NODE_ID=node-1
      - NODE_NAME=Server-1
      - LISTEN_ADDR=0.0.0.0:7000
      - WS_ADDR=0.0.0.0:7001
      - UDP_ADDR=0.0.0.0:7002
      - QUIC_ADDR=0.0.0.0:7003
      - API_ADDR=0.0.0.0:8080
      - STORAGE_TYPE=redis
      - STORAGE_REDIS_ADDR=redis:6379
      - MESSAGE_BROKER_TYPE=redis
      - MESSAGE_BROKER_REDIS_ADDR=redis:6379
      - LOG_LEVEL=info
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - tunnox-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Tunnox Server å®ä¾‹2
  tunnox-server-2:
    build:
      context: ../..
      dockerfile: Dockerfile.server
    environment:
      - NODE_ID=node-2
      - NODE_NAME=Server-2
      - LISTEN_ADDR=0.0.0.0:7000
      - WS_ADDR=0.0.0.0:7001
      - UDP_ADDR=0.0.0.0:7002
      - QUIC_ADDR=0.0.0.0:7003
      - API_ADDR=0.0.0.0:8080
      - STORAGE_TYPE=redis
      - STORAGE_REDIS_ADDR=redis:6379
      - MESSAGE_BROKER_TYPE=redis
      - MESSAGE_BROKER_REDIS_ADDR=redis:6379
      - LOG_LEVEL=info
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - tunnox-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Tunnox Server å®ä¾‹3
  tunnox-server-3:
    build:
      context: ../..
      dockerfile: Dockerfile.server
    environment:
      - NODE_ID=node-3
      - NODE_NAME=Server-3
      - LISTEN_ADDR=0.0.0.0:7000
      - WS_ADDR=0.0.0.0:7001
      - UDP_ADDR=0.0.0.0:7002
      - QUIC_ADDR=0.0.0.0:7003
      - API_ADDR=0.0.0.0:8080
      - STORAGE_TYPE=redis
      - STORAGE_REDIS_ADDR=redis:6379
      - MESSAGE_BROKER_TYPE=redis
      - MESSAGE_BROKER_REDIS_ADDR=redis:6379
      - LOG_LEVEL=info
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - tunnox-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Tunnox Server å®ä¾‹4 (å¯é€‰ï¼Œç”¨äºæ‰©å®¹æµ‹è¯•)
  tunnox-server-4:
    build:
      context: ../..
      dockerfile: Dockerfile.server
    environment:
      - NODE_ID=node-4
      - NODE_NAME=Server-4
      - LISTEN_ADDR=0.0.0.0:7000
      - WS_ADDR=0.0.0.0:7001
      - UDP_ADDR=0.0.0.0:7002
      - QUIC_ADDR=0.0.0.0:7003
      - API_ADDR=0.0.0.0:8080
      - STORAGE_TYPE=redis
      - STORAGE_REDIS_ADDR=redis:6379
      - MESSAGE_BROKER_TYPE=redis
      - MESSAGE_BROKER_REDIS_ADDR=redis:6379
      - LOG_LEVEL=info
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - tunnox-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    profiles:
      - scale  # ä»…åœ¨æ‰©å®¹æµ‹è¯•æ—¶å¯åŠ¨

  # Tunnox Server å®ä¾‹5 (å¯é€‰ï¼Œç”¨äºæ‰©å®¹æµ‹è¯•)
  tunnox-server-5:
    build:
      context: ../..
      dockerfile: Dockerfile.server
    environment:
      - NODE_ID=node-5
      - NODE_NAME=Server-5
      - LISTEN_ADDR=0.0.0.0:7000
      - WS_ADDR=0.0.0.0:7001
      - UDP_ADDR=0.0.0.0:7002
      - QUIC_ADDR=0.0.0.0:7003
      - API_ADDR=0.0.0.0:8080
      - STORAGE_TYPE=redis
      - STORAGE_REDIS_ADDR=redis:6379
      - MESSAGE_BROKER_TYPE=redis
      - MESSAGE_BROKER_REDIS_ADDR=redis:6379
      - LOG_LEVEL=info
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - tunnox-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    profiles:
      - scale  # ä»…åœ¨æ‰©å®¹æµ‹è¯•æ—¶å¯åŠ¨

  # Nginx è´Ÿè½½å‡è¡¡å™¨
  nginx:
    image: nginx:alpine
    ports:
      - "7000:7000"   # TCP
      - "7001:7001"   # WebSocket
      - "7002:7002/udp"   # UDP
      - "7003:7003/udp"   # QUIC
      - "8080:8080"   # Management API
    volumes:
      - ./nginx/load-balancer.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      tunnox-server-1:
        condition: service_healthy
      tunnox-server-2:
        condition: service_healthy
      tunnox-server-3:
        condition: service_healthy
    networks:
      - tunnox-net

  # æµ‹è¯•ç›®æ ‡æœåŠ¡ - Nginx (ç”¨äºéªŒè¯éš§é“è½¬å‘)
  nginx-target:
    image: nginx:alpine
    volumes:
      - ./nginx/html:/usr/share/nginx/html:ro
    networks:
      - tunnox-net

  # æµ‹è¯•ç›®æ ‡æœåŠ¡ - PostgreSQL
  postgres-target:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: dtcpay
      POSTGRES_DB: testdb
    networks:
      - tunnox-net

networks:
  tunnox-net:
    driver: bridge
```

#### Nginx è´Ÿè½½å‡è¡¡é…ç½®

**æ–‡ä»¶**: `tests/e2e/nginx/load-balancer.conf`

```nginx
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 10000;
    use epoll;
}

stream {
    # TCP è´Ÿè½½å‡è¡¡ (ç«¯å£ 7000)
    upstream tunnox_tcp {
        # è´Ÿè½½å‡è¡¡ç­–ç•¥: least_conn (æœ€å°‘è¿æ¥)
        least_conn;
        
        server tunnox-server-1:7000 max_fails=3 fail_timeout=30s;
        server tunnox-server-2:7000 max_fails=3 fail_timeout=30s;
        server tunnox-server-3:7000 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 7000;
        proxy_pass tunnox_tcp;
        proxy_timeout 3600s;
        proxy_connect_timeout 10s;
    }

    # UDP è´Ÿè½½å‡è¡¡ (ç«¯å£ 7002)
    upstream tunnox_udp {
        # UDP ä½¿ç”¨ hash ç­–ç•¥ä¿è¯åŒä¸€å®¢æˆ·ç«¯åˆ°åŒä¸€åç«¯
        hash $remote_addr consistent;
        
        server tunnox-server-1:7002 max_fails=3 fail_timeout=30s;
        server tunnox-server-2:7002 max_fails=3 fail_timeout=30s;
        server tunnox-server-3:7002 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 7002 udp;
        proxy_pass tunnox_udp;
        proxy_timeout 30s;
        proxy_responses 1;
    }

    # QUIC è´Ÿè½½å‡è¡¡ (ç«¯å£ 7003)
    upstream tunnox_quic {
        hash $remote_addr consistent;
        
        server tunnox-server-1:7003 max_fails=3 fail_timeout=30s;
        server tunnox-server-2:7003 max_fails=3 fail_timeout=30s;
        server tunnox-server-3:7003 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 7003 udp;
        proxy_pass tunnox_quic;
        proxy_timeout 30s;
        proxy_responses 1;
    }
}

http {
    # WebSocket è´Ÿè½½å‡è¡¡ (ç«¯å£ 7001)
    upstream tunnox_ws {
        # WebSocket éœ€è¦ä¿æŒè¿æ¥ï¼Œä½¿ç”¨ ip_hash
        ip_hash;
        
        server tunnox-server-1:7001 max_fails=3 fail_timeout=30s;
        server tunnox-server-2:7001 max_fails=3 fail_timeout=30s;
        server tunnox-server-3:7001 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 7001;
        
        location / {
            proxy_pass http://tunnox_ws;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_read_timeout 3600s;
        }
    }

    # Management API è´Ÿè½½å‡è¡¡ (ç«¯å£ 8080)
    upstream tunnox_api {
        # API ä½¿ç”¨è½®è¯¢
        least_conn;
        
        server tunnox-server-1:8080 max_fails=3 fail_timeout=30s;
        server tunnox-server-2:8080 max_fails=3 fail_timeout=30s;
        server tunnox-server-3:8080 max_fails=3 fail_timeout=30s;
    }

    server {
        listen 8080;
        
        location / {
            proxy_pass http://tunnox_api;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }

        # å¥åº·æ£€æŸ¥ç«¯ç‚¹ä¸èµ°è´Ÿè½½å‡è¡¡ï¼Œç›´æ¥è¿”å›
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

#### æµ‹è¯•ç”¨ä¾‹

**æ–‡ä»¶**: `tests/e2e/load_balancer_test.go`

```go
package e2e

import (
    "context"
    "fmt"
    "net/http"
    "sync"
    "testing"
    "time"
    
    "github.com/stretchr/testify/assert"
    "github.com/stretchr/testify/require"
)

// TestLoadBalancer_ControlAndTunnelSeparation æµ‹è¯•æ§åˆ¶è¿æ¥å’Œéš§é“è¿æ¥åˆ†ç¦»
func TestLoadBalancer_ControlAndTunnelSeparation(t *testing.T) {
    if testing.Short() {
        t.Skip("Skipping E2E load balancer test in short mode")
    }
    
    // 1. å¯åŠ¨ç¯å¢ƒ (3ä¸ªServer + Nginx LB)
    compose := NewDockerComposeEnv(t, "docker-compose.load-balancer.yml")
    defer compose.Cleanup()
    
    // 2. ç­‰å¾…æ‰€æœ‰Serverå°±ç»ª
    compose.WaitForHealthy("tunnox-server-1", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-2", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-3", 30*time.Second)
    compose.WaitForHealthy("nginx", 10*time.Second)
    
    // 3. åˆ›å»ºå¤šä¸ªå®¢æˆ·ç«¯è¿æ¥
    clients := make([]*TestClient, 10)
    for i := 0; i < 10; i++ {
        client := NewTestClient(t, &ClientConfig{
            Protocol: "tcp",
            ServerAddr: "localhost:7000", // é€šè¿‡Nginxè´Ÿè½½å‡è¡¡
        })
        clients[i] = client
        require.NoError(t, client.Connect())
    }
    
    // 4. æŸ¥è¯¢æ¯ä¸ªå®¢æˆ·ç«¯çš„æ§åˆ¶è¿æ¥æ‰€åœ¨Server
    apiClient := compose.GetAPIClient("http://localhost:8080")
    
    serverDistribution := make(map[string]int)
    for i, client := range clients {
        clientInfo, err := apiClient.GetClient(client.ID)
        require.NoError(t, err)
        
        nodeID := clientInfo.NodeID
        serverDistribution[nodeID]++
        
        t.Logf("Client %d: control connection on %s", i, nodeID)
    }
    
    // 5. éªŒè¯è´Ÿè½½åˆ†å¸ƒï¼ˆè‡³å°‘2ä¸ªServeræœ‰è¿æ¥ï¼‰
    assert.GreaterOrEqual(t, len(serverDistribution), 2, 
        "Control connections should be distributed across at least 2 servers")
    
    // 6. åˆ›å»ºæ˜ å°„ï¼ˆå®¢æˆ·ç«¯0 -> å®¢æˆ·ç«¯5ï¼‰
    mapping, err := apiClient.CreateMapping(&MappingRequest{
        SourceClientID: clients[0].ID,
        TargetClientID: clients[5].ID,
        Protocol:       "tcp",
        TargetHost:     "nginx-target",
        TargetPort:     80,
    })
    require.NoError(t, err)
    
    // 7. ç­‰å¾…æ˜ å°„ç”Ÿæ•ˆ
    time.Sleep(2 * time.Second)
    
    // 8. å»ºç«‹å¤šä¸ªéš§é“è¿æ¥
    var wg sync.WaitGroup
    tunnelCount := 20
    successCount := 0
    var mu sync.Mutex
    
    for i := 0; i < tunnelCount; i++ {
        wg.Add(1)
        go func(idx int) {
            defer wg.Done()
            
            // é€šè¿‡æ˜ å°„çš„æºç«¯å£è®¿é—®
            resp, err := http.Get(fmt.Sprintf("http://localhost:%d", mapping.SourcePort))
            if err != nil {
                t.Logf("Tunnel %d: failed to connect: %v", idx, err)
                return
            }
            defer resp.Body.Close()
            
            if resp.StatusCode == 200 {
                mu.Lock()
                successCount++
                mu.Unlock()
            }
        }(i)
    }
    
    wg.Wait()
    
    // 9. éªŒè¯æ‰€æœ‰éš§é“è¿æ¥æˆåŠŸ
    assert.Equal(t, tunnelCount, successCount, 
        "All tunnel connections should succeed even when distributed across servers")
    
    // 10. æŸ¥è¯¢éš§é“è¿æ¥åˆ†å¸ƒ
    connections, err := apiClient.GetMappingConnections(mapping.ID)
    require.NoError(t, err)
    
    tunnelServerDist := make(map[string]int)
    for _, conn := range connections {
        tunnelServerDist[conn.NodeID]++
    }
    
    t.Logf("Tunnel distribution: %v", tunnelServerDist)
    
    // 11. éªŒè¯éš§é“è¿æ¥åˆ†å¸ƒåˆ°äº†å¤šä¸ªServer
    assert.GreaterOrEqual(t, len(tunnelServerDist), 2, 
        "Tunnel connections should be distributed across multiple servers")
}

// TestLoadBalancer_CrossServerMessaging æµ‹è¯•è·¨Serveræ¶ˆæ¯ä¼ é€’
func TestLoadBalancer_CrossServerMessaging(t *testing.T) {
    if testing.Short() {
        t.Skip("Skipping E2E load balancer test in short mode")
    }
    
    compose := NewDockerComposeEnv(t, "docker-compose.load-balancer.yml")
    defer compose.Cleanup()
    
    compose.WaitForHealthy("tunnox-server-1", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-2", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-3", 30*time.Second)
    
    apiClient := compose.GetAPIClient("http://localhost:8080")
    
    // åˆ›å»ºç”¨æˆ·å’Œå®¢æˆ·ç«¯
    user, err := apiClient.CreateUser("testuser", "test@example.com")
    require.NoError(t, err)
    
    // åˆ›å»ºæ˜ å°„
    mapping, err := apiClient.CreateMapping(&MappingRequest{
        UserID:         user.ID,
        SourceClientID: 1,
        TargetClientID: 2,
        Protocol:       "tcp",
        TargetHost:     "nginx-target",
        TargetPort:     80,
    })
    require.NoError(t, err)
    
    // ç­‰å¾…é…ç½®æ¨é€é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—ä¼ é€’åˆ°æ‰€æœ‰Server
    time.Sleep(3 * time.Second)
    
    // ä»ä¸åŒçš„ServeræŸ¥è¯¢æ˜ å°„ä¿¡æ¯ï¼Œåº”è¯¥éƒ½èƒ½æŸ¥åˆ°
    for i := 1; i <= 3; i++ {
        serverAPI := compose.GetAPIClient(fmt.Sprintf("http://tunnox-server-%d:8080", i))
        
        fetchedMapping, err := serverAPI.GetMapping(mapping.ID)
        require.NoError(t, err, "Server %d should have the mapping", i)
        assert.Equal(t, mapping.ID, fetchedMapping.ID)
        
        t.Logf("âœ“ Server-%d has mapping %s", i, mapping.ID)
    }
    
    // æ›´æ–°æ˜ å°„
    mapping.Status = "disabled"
    err = apiClient.UpdateMapping(mapping)
    require.NoError(t, err)
    
    // ç­‰å¾…æ›´æ–°ä¼ æ’­
    time.Sleep(2 * time.Second)
    
    // éªŒè¯æ‰€æœ‰Serveréƒ½æ”¶åˆ°äº†æ›´æ–°
    for i := 1; i <= 3; i++ {
        serverAPI := compose.GetAPIClient(fmt.Sprintf("http://tunnox-server-%d:8080", i))
        
        fetchedMapping, err := serverAPI.GetMapping(mapping.ID)
        require.NoError(t, err)
        assert.Equal(t, "disabled", string(fetchedMapping.Status))
        
        t.Logf("âœ“ Server-%d received mapping update", i)
    }
}

// TestLoadBalancer_NodeFailover æµ‹è¯•èŠ‚ç‚¹æ•…éšœè½¬ç§»
func TestLoadBalancer_NodeFailover(t *testing.T) {
    if testing.Short() {
        t.Skip("Skipping E2E load balancer test in short mode")
    }
    
    compose := NewDockerComposeEnv(t, "docker-compose.load-balancer.yml")
    defer compose.Cleanup()
    
    compose.WaitForHealthy("tunnox-server-1", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-2", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-3", 30*time.Second)
    
    // åˆ›å»ºå®¢æˆ·ç«¯
    client := NewTestClient(t, &ClientConfig{
        Protocol:   "tcp",
        ServerAddr: "localhost:7000",
        AutoReconnect: true,
    })
    require.NoError(t, client.Connect())
    
    apiClient := compose.GetAPIClient("http://localhost:8080")
    
    // æŸ¥è¯¢å®¢æˆ·ç«¯è¿æ¥çš„Server
    clientInfo, err := apiClient.GetClient(client.ID)
    require.NoError(t, err)
    originalNode := clientInfo.NodeID
    
    t.Logf("Client initially connected to %s", originalNode)
    
    // åˆ›å»ºæ˜ å°„å¹¶éªŒè¯å·¥ä½œæ­£å¸¸
    mapping, err := apiClient.CreateMapping(&MappingRequest{
        SourceClientID: client.ID,
        TargetClientID: 99999, // å‡è®¾å­˜åœ¨
        Protocol:       "tcp",
        TargetHost:     "nginx-target",
        TargetPort:     80,
    })
    require.NoError(t, err)
    
    // åœæ­¢å®¢æˆ·ç«¯è¿æ¥çš„Server
    t.Logf("Stopping %s...", originalNode)
    compose.StopService(originalNode)
    
    // ç­‰å¾…å®¢æˆ·ç«¯é‡è¿åˆ°å…¶ä»–Server
    time.Sleep(5 * time.Second)
    
    // éªŒè¯å®¢æˆ·ç«¯å·²é‡è¿
    clientInfo, err = apiClient.GetClient(client.ID)
    require.NoError(t, err)
    newNode := clientInfo.NodeID
    
    assert.NotEqual(t, originalNode, newNode, "Client should reconnect to a different server")
    assert.Equal(t, "online", clientInfo.Status, "Client should be online after reconnection")
    
    t.Logf("âœ“ Client reconnected to %s", newNode)
    
    // éªŒè¯æ˜ å°„ä»ç„¶å­˜åœ¨ä¸”å¯è®¿é—®
    fetchedMapping, err := apiClient.GetMapping(mapping.ID)
    require.NoError(t, err)
    assert.Equal(t, mapping.ID, fetchedMapping.ID)
    
    t.Logf("âœ“ Mapping still accessible after node failure")
}

// TestLoadBalancer_DifferentStrategies æµ‹è¯•ä¸åŒçš„è´Ÿè½½å‡è¡¡ç­–ç•¥
func TestLoadBalancer_DifferentStrategies(t *testing.T) {
    strategies := []struct {
        name           string
        nginxConfig    string
        expectedBehavior string
    }{
        {
            name:           "round-robin",
            nginxConfig:    "round-robin.conf",
            expectedBehavior: "å‡åŒ€åˆ†å¸ƒ",
        },
        {
            name:           "least-conn",
            nginxConfig:    "least-conn.conf",
            expectedBehavior: "å€¾å‘è¿æ¥æ•°å°‘çš„Server",
        },
        {
            name:           "ip-hash",
            nginxConfig:    "ip-hash.conf",
            expectedBehavior: "ç›¸åŒIPåˆ°ç›¸åŒServer",
        },
    }
    
    for _, strategy := range strategies {
        t.Run(strategy.name, func(t *testing.T) {
            // ä¸ºæ¯ä¸ªç­–ç•¥å¯åŠ¨ç‹¬ç«‹çš„æµ‹è¯•ç¯å¢ƒ
            compose := NewDockerComposeEnv(t, "docker-compose.load-balancer.yml")
            defer compose.Cleanup()
            
            // æ›´æ–°Nginxé…ç½®
            compose.UpdateNginxConfig(strategy.nginxConfig)
            
            // åˆ›å»ºå¤§é‡å®¢æˆ·ç«¯
            clientCount := 100
            clients := make([]*TestClient, clientCount)
            
            for i := 0; i < clientCount; i++ {
                client := NewTestClient(t, &ClientConfig{
                    Protocol:   "tcp",
                    ServerAddr: "localhost:7000",
                })
                require.NoError(t, client.Connect())
                clients[i] = client
            }
            
            // ç»Ÿè®¡åˆ†å¸ƒ
            apiClient := compose.GetAPIClient("http://localhost:8080")
            distribution := make(map[string]int)
            
            for _, client := range clients {
                clientInfo, err := apiClient.GetClient(client.ID)
                require.NoError(t, err)
                distribution[clientInfo.NodeID]++
            }
            
            t.Logf("Strategy: %s", strategy.name)
            t.Logf("Distribution: %v", distribution)
            t.Logf("Expected behavior: %s", strategy.expectedBehavior)
            
            // éªŒè¯æ‰€æœ‰Serveréƒ½æœ‰è¿æ¥
            assert.Equal(t, 3, len(distribution), 
                "All 3 servers should have connections")
        })
    }
}

// TestLoadBalancer_HighConcurrency æµ‹è¯•é«˜å¹¶å‘åœºæ™¯
func TestLoadBalancer_HighConcurrency(t *testing.T) {
    if testing.Short() {
        t.Skip("Skipping E2E load balancer test in short mode")
    }
    
    compose := NewDockerComposeEnv(t, "docker-compose.load-balancer.yml")
    defer compose.Cleanup()
    
    compose.WaitForHealthy("tunnox-server-1", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-2", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-3", 30*time.Second)
    
    apiClient := compose.GetAPIClient("http://localhost:8080")
    
    // åˆ›å»ºæ˜ å°„
    mapping, err := apiClient.CreateMapping(&MappingRequest{
        SourceClientID: 1,
        TargetClientID: 2,
        Protocol:       "tcp",
        TargetHost:     "nginx-target",
        TargetPort:     80,
    })
    require.NoError(t, err)
    
    time.Sleep(2 * time.Second)
    
    // å¹¶å‘å»ºç«‹1000ä¸ªè¿æ¥
    concurrentConns := 1000
    var wg sync.WaitGroup
    successCount := int64(0)
    failCount := int64(0)
    
    start := time.Now()
    
    for i := 0; i < concurrentConns; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            
            resp, err := http.Get(fmt.Sprintf("http://localhost:%d", mapping.SourcePort))
            if err != nil {
                atomic.AddInt64(&failCount, 1)
                return
            }
            defer resp.Body.Close()
            
            if resp.StatusCode == 200 {
                atomic.AddInt64(&successCount, 1)
            } else {
                atomic.AddInt64(&failCount, 1)
            }
        }()
    }
    
    wg.Wait()
    duration := time.Since(start)
    
    t.Logf("Concurrent connections: %d", concurrentConns)
    t.Logf("Success: %d, Failed: %d", successCount, failCount)
    t.Logf("Duration: %v", duration)
    t.Logf("QPS: %.2f", float64(concurrentConns)/duration.Seconds())
    
    // éªŒè¯æˆåŠŸç‡ > 95%
    successRate := float64(successCount) / float64(concurrentConns) * 100
    assert.Greater(t, successRate, 95.0, 
        "Success rate should be > 95% in load balanced environment")
}

// TestLoadBalancer_DynamicScaling æµ‹è¯•åŠ¨æ€æ‰©ç¼©å®¹
func TestLoadBalancer_DynamicScaling(t *testing.T) {
    if testing.Short() {
        t.Skip("Skipping E2E load balancer test in short mode")
    }
    
    compose := NewDockerComposeEnv(t, "docker-compose.load-balancer.yml")
    defer compose.Cleanup()
    
    // åˆå§‹åªå¯åŠ¨2ä¸ªServer
    compose.WaitForHealthy("tunnox-server-1", 30*time.Second)
    compose.WaitForHealthy("tunnox-server-2", 30*time.Second)
    
    apiClient := compose.GetAPIClient("http://localhost:8080")
    
    // åˆ›å»º50ä¸ªå®¢æˆ·ç«¯
    clients := createClients(t, 50, "localhost:7000")
    
    // ç»Ÿè®¡åˆå§‹åˆ†å¸ƒï¼ˆåº”è¯¥åˆ†å¸ƒåœ¨2ä¸ªServerä¸Šï¼‰
    dist1 := getClientDistribution(t, apiClient, clients)
    assert.Equal(t, 2, len(dist1), "Should distribute across 2 servers initially")
    t.Logf("Initial distribution (2 servers): %v", dist1)
    
    // æ‰©å®¹ï¼šå¯åŠ¨ç¬¬3ä¸ªServer
    t.Log("Scaling up: starting server-3...")
    compose.StartService("tunnox-server-3")
    compose.WaitForHealthy("tunnox-server-3", 30*time.Second)
    
    // æ›´æ–°Nginxé…ç½®ä»¥åŒ…å«æ–°Serverï¼ˆæˆ–ç­‰å¾…Nginxè‡ªåŠ¨æ£€æµ‹ï¼‰
    compose.ReloadNginx()
    
    // åˆ›å»ºæ›´å¤šå®¢æˆ·ç«¯
    newClients := createClients(t, 50, "localhost:7000")
    clients = append(clients, newClients...)
    
    // ç»Ÿè®¡æ‰©å®¹ååˆ†å¸ƒï¼ˆåº”è¯¥åˆ†å¸ƒåœ¨3ä¸ªServerä¸Šï¼‰
    dist2 := getClientDistribution(t, apiClient, clients)
    assert.Equal(t, 3, len(dist2), "Should distribute across 3 servers after scaling")
    t.Logf("After scaling up (3 servers): %v", dist2)
    
    // ç¼©å®¹ï¼šåœæ­¢Server-1
    t.Log("Scaling down: stopping server-1...")
    compose.StopService("tunnox-server-1")
    
    // ç­‰å¾…å®¢æˆ·ç«¯é‡è¿
    time.Sleep(10 * time.Second)
    
    // ç»Ÿè®¡ç¼©å®¹ååˆ†å¸ƒï¼ˆåº”è¯¥åˆ†å¸ƒåœ¨2ä¸ªServerä¸Šï¼‰
    dist3 := getClientDistribution(t, apiClient, clients)
    assert.Equal(t, 2, len(dist3), "Should distribute across 2 servers after scaling down")
    assert.NotContains(t, dist3, "node-1", "Should not have clients on stopped server")
    t.Logf("After scaling down (2 servers): %v", dist3)
}

// è¾…åŠ©å‡½æ•°
func createClients(t *testing.T, count int, serverAddr string) []*TestClient {
    clients := make([]*TestClient, count)
    for i := 0; i < count; i++ {
        client := NewTestClient(t, &ClientConfig{
            Protocol:   "tcp",
            ServerAddr: serverAddr,
        })
        require.NoError(t, client.Connect())
        clients[i] = client
    }
    return clients
}

func getClientDistribution(t *testing.T, apiClient *APIClient, clients []*TestClient) map[string]int {
    dist := make(map[string]int)
    for _, client := range clients {
        clientInfo, err := apiClient.GetClient(client.ID)
        if err != nil {
            continue // å®¢æˆ·ç«¯å¯èƒ½å·²æ–­å¼€
        }
        dist[clientInfo.NodeID]++
    }
    return dist
}
```

---

## ğŸ¯ å…³é”®æµ‹è¯•åœºæ™¯

### 1. æ§åˆ¶è¿æ¥å’Œéš§é“è¿æ¥åˆ†ç¦» â­â­â­â­â­

**åœºæ™¯**:
```
å®¢æˆ·ç«¯Açš„æ§åˆ¶è¿æ¥ â†’ Nginx â†’ Server-1
å®¢æˆ·ç«¯Bçš„æ§åˆ¶è¿æ¥ â†’ Nginx â†’ Server-2
Aâ†’Bçš„éš§é“è¿æ¥     â†’ Nginx â†’ Server-3
```

**éªŒè¯ç‚¹**:
- âœ… Server-3éœ€è¦èƒ½æŸ¥è¯¢åˆ°Server-1çš„å®¢æˆ·ç«¯Aä¿¡æ¯ï¼ˆé€šè¿‡Redisï¼‰
- âœ… Server-3éœ€è¦èƒ½æŸ¥è¯¢åˆ°Server-2çš„å®¢æˆ·ç«¯Bä¿¡æ¯ï¼ˆé€šè¿‡Redisï¼‰
- âœ… TunnelOpenè¯·æ±‚éœ€è¦é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—è·¯ç”±åˆ°Server-2
- âœ… æ•°æ®è½¬å‘æ­£å¸¸å·¥ä½œ

**é¢„æœŸè¡Œä¸º**:
- Server-3æ”¶åˆ°TunnelOpenè¯·æ±‚åï¼Œä»RedisæŸ¥è¯¢ç›®æ ‡å®¢æˆ·ç«¯Bçš„æ§åˆ¶è¿æ¥æ‰€åœ¨èŠ‚ç‚¹
- Server-3é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—å‘é€TunnelOpenåˆ°Server-2
- Server-2é€šè¿‡å®¢æˆ·ç«¯Bçš„æ§åˆ¶è¿æ¥å‘é€TunnelOpenå‘½ä»¤
- å®¢æˆ·ç«¯Bå»ºç«‹éš§é“è¿æ¥ï¼Œå¯èƒ½åˆ°Server-1/2/3ä¸­çš„ä»»æ„ä¸€ä¸ª
- æ•°æ®é€šè¿‡Serveré—´çš„æ¡¥æ¥æ­£å¸¸è½¬å‘

### 2. é…ç½®æ¨é€è·¨Server â­â­â­â­

**åœºæ™¯**:
```
ç®¡ç†å‘˜é€šè¿‡APIï¼ˆåˆ°Server-1ï¼‰åˆ›å»ºæ˜ å°„
å®¢æˆ·ç«¯Aè¿æ¥åœ¨Server-2
å®¢æˆ·ç«¯Bè¿æ¥åœ¨Server-3
```

**éªŒè¯ç‚¹**:
- âœ… Server-1å°†æ˜ å°„é…ç½®å†™å…¥Redis
- âœ… Server-1é€šè¿‡æ¶ˆæ¯é˜Ÿåˆ—å¹¿æ’­é…ç½®æ›´æ–°
- âœ… Server-2å’ŒServer-3æ”¶åˆ°æ¶ˆæ¯å¹¶æ¨é€ç»™å„è‡ªçš„å®¢æˆ·ç«¯
- âœ… æ‰€æœ‰å®¢æˆ·ç«¯éƒ½æ”¶åˆ°æœ€æ–°é…ç½®

### 3. èŠ‚ç‚¹æ•…éšœè½¬ç§» â­â­â­â­â­

**åœºæ™¯**:
```
å®¢æˆ·ç«¯Aè¿æ¥åœ¨Server-1
Server-1å´©æºƒ
```

**éªŒè¯ç‚¹**:
- âœ… Nginxæ£€æµ‹åˆ°Server-1ä¸å¥åº·ï¼Œåœæ­¢è½¬å‘è¯·æ±‚åˆ°Server-1
- âœ… å®¢æˆ·ç«¯Aè‡ªåŠ¨é‡è¿åˆ°Server-2æˆ–Server-3
- âœ… å®¢æˆ·ç«¯Açš„æ˜ å°„é…ç½®ä»Redisæ¢å¤
- âœ… ç°æœ‰çš„éš§é“è¿æ¥ä¸å—å½±å“ï¼ˆå¦‚æœä¸åœ¨Server-1ä¸Šï¼‰

### 4. è´Ÿè½½å‡è¡¡ç­–ç•¥å·®å¼‚ â­â­â­

**ç­–ç•¥å¯¹æ¯”**:

| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|------|------|---------|
| **Round-robin** | å‡åŒ€åˆ†å¸ƒï¼Œç®€å• | ä¸è€ƒè™‘Serverè´Ÿè½½ | åŒè´¨åŒ–Server |
| **Least-conn** | è´Ÿè½½æ›´å‡è¡¡ | éœ€è¦ç»´æŠ¤è¿æ¥æ•°çŠ¶æ€ | è¿æ¥ç”Ÿå‘½å‘¨æœŸé•¿çš„åœºæ™¯ |
| **IP-hash** | ä¼šè¯ä¿æŒ | åˆ†å¸ƒå¯èƒ½ä¸å‡ | éœ€è¦ä¼šè¯ç²˜æ€§ |
| **Hash (ä¸€è‡´æ€§å“ˆå¸Œ)** | æ‰©ç¼©å®¹å½±å“å° | å®ç°å¤æ‚ | åŠ¨æ€æ‰©ç¼©å®¹åœºæ™¯ |

**æµ‹è¯•éªŒè¯**:
- âœ… æ¯ç§ç­–ç•¥ä¸‹å®¢æˆ·ç«¯åˆ†å¸ƒç¬¦åˆé¢„æœŸ
- âœ… æ˜ å°„è¿æ¥èƒ½æ­£å¸¸å»ºç«‹å’Œè½¬å‘
- âœ… é…ç½®æ¨é€æ­£å¸¸å·¥ä½œ

### 5. åŠ¨æ€æ‰©ç¼©å®¹ â­â­â­â­

**æ‰©å®¹åœºæ™¯**:
```
åˆå§‹: 3ä¸ªServer
æ‰©å®¹: æ–°å¢2ä¸ªServer (æ€»å…±5ä¸ª)
```

**éªŒè¯ç‚¹**:
- âœ… æ–°ServeråŠ å…¥åï¼Œæ–°è¿æ¥å¼€å§‹åˆ†é…åˆ°æ–°Server
- âœ… ç°æœ‰è¿æ¥ä¸å—å½±å“
- âœ… é…ç½®åŒæ­¥åˆ°æ–°Server
- âœ… æ–°Serverèƒ½æ­£å¸¸å¤„ç†éš§é“è¯·æ±‚

**ç¼©å®¹åœºæ™¯**:
```
åˆå§‹: 5ä¸ªServer
ç¼©å®¹: åœæ­¢2ä¸ªServer (å‰©ä½™3ä¸ª)
```

**éªŒè¯ç‚¹**:
- âœ… åœæ­¢Serverä¸Šçš„å®¢æˆ·ç«¯è‡ªåŠ¨é‡è¿åˆ°å…¶ä»–Server
- âœ… Nginxåœæ­¢è½¬å‘åˆ°å·²åœæ­¢çš„Server
- âœ… éš§é“è¿æ¥è¿ç§»æˆ–é‡å»º
- âœ… æ— æ•°æ®ä¸¢å¤±

### 6. é«˜å¹¶å‘å‹åŠ›æµ‹è¯• â­â­â­â­â­

**åœºæ™¯**:
```
1000ä¸ªå®¢æˆ·ç«¯åŒæ—¶è¿æ¥
æ¯ä¸ªå®¢æˆ·ç«¯å»ºç«‹10ä¸ªéš§é“
æ€»è®¡10000ä¸ªå¹¶å‘éš§é“è¿æ¥
```

**éªŒè¯ç‚¹**:
- âœ… æˆåŠŸç‡ > 95%
- âœ… å¹³å‡å»¶è¿Ÿ < 20ms
- âœ… P99å»¶è¿Ÿ < 100ms
- âœ… ååé‡ > 500MB/s
- âœ… è´Ÿè½½å‡åŒ€åˆ†å¸ƒ
- âœ… æ— å†…å­˜æ³„æ¼
- âœ… æ— æ­»é”

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### ç›®æ ‡æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å•èŠ‚ç‚¹ | 3èŠ‚ç‚¹é›†ç¾¤ | 5èŠ‚ç‚¹é›†ç¾¤ |
|------|--------|----------|----------|
| **æœ€å¤§å¹¶å‘è¿æ¥** | 10,000 | 30,000 | 50,000 |
| **æœ€å¤§éš§é“æ•°** | 5,000 | 15,000 | 25,000 |
| **å¹³å‡å»¶è¿Ÿ** | <10ms | <15ms | <20ms |
| **P99å»¶è¿Ÿ** | <50ms | <80ms | <100ms |
| **ååé‡** | 200MB/s | 500MB/s | 800MB/s |
| **è¿æ¥å»ºç«‹é€Ÿç‡** | 1000/s | 2500/s | 4000/s |

### æ€§èƒ½æµ‹è¯•è„šæœ¬

**æ–‡ä»¶**: `tests/e2e/benchmark_load_balancer.sh`

```bash
#!/bin/bash

echo "ğŸš€ Starting Load Balancer Performance Benchmark..."

# å¯åŠ¨ç¯å¢ƒ
docker-compose -f docker-compose.load-balancer.yml up -d
sleep 30

# ç­‰å¾…æ‰€æœ‰æœåŠ¡å°±ç»ª
for i in 1 2 3; do
    until curl -f http://localhost:8080/health; do
        echo "Waiting for server $i..."
        sleep 2
    done
done

echo "âœ… All servers ready"

# æ€§èƒ½æµ‹è¯•1: è¿æ¥å»ºç«‹é€Ÿç‡
echo "ğŸ“Š Test 1: Connection Establishment Rate"
wrk -t10 -c1000 -d30s --latency \
    -s benchmark/connect.lua \
    http://localhost:7000

# æ€§èƒ½æµ‹è¯•2: éš§é“ååé‡
echo "ğŸ“Š Test 2: Tunnel Throughput"
iperf3 -c localhost -p 9000 -t 60 -P 100

# æ€§èƒ½æµ‹è¯•3: APIå“åº”æ—¶é—´
echo "ğŸ“Š Test 3: API Response Time"
wrk -t10 -c100 -d30s --latency \
    http://localhost:8080/api/v1/stats/system

# æ€§èƒ½æµ‹è¯•4: æ¶ˆæ¯é˜Ÿåˆ—å»¶è¿Ÿ
echo "ğŸ“Š Test 4: Message Queue Latency"
go test -v -run=TestLoadBalancer_MessageLatency \
    -benchtime=30s ./tests/e2e/

# æ¸…ç†
docker-compose -f docker-compose.load-balancer.yml down

echo "âœ… Benchmark complete"
```

---

## ğŸ”§ è°ƒè¯•å’Œç›‘æ§

### 1. Redisç›‘æ§

**æŸ¥çœ‹æ‰€æœ‰Session**:
```bash
docker exec -it redis redis-cli
> KEYS tunnox:session:*
> HGETALL tunnox:session:12345
```

**æŸ¥çœ‹æ¶ˆæ¯é˜Ÿåˆ—**:
```bash
> LLEN tunnox:mq:tunnel_open
> LRANGE tunnox:mq:tunnel_open 0 -1
```

### 2. æŸ¥çœ‹Serveræ—¥å¿—

```bash
# æŸ¥çœ‹æ‰€æœ‰Serveræ—¥å¿—
docker-compose logs -f tunnox-server-1 tunnox-server-2 tunnox-server-3

# æŸ¥çœ‹ç‰¹å®šServerçš„é”™è¯¯æ—¥å¿—
docker-compose logs tunnox-server-1 | grep ERROR

# æŸ¥çœ‹Nginxè®¿é—®æ—¥å¿—
docker-compose logs nginx | grep "proxy"
```

### 3. æµé‡åˆ†æ

**æŸ¥çœ‹Nginxè¿æ¥åˆ†å¸ƒ**:
```bash
# è¿›å…¥Nginxå®¹å™¨
docker exec -it nginx sh

# æŸ¥çœ‹upstreamçŠ¶æ€ï¼ˆéœ€è¦ngx_http_upstream_moduleï¼‰
curl http://localhost:8080/upstream_status
```

### 4. æ€§èƒ½åˆ†æ

**æŸ¥çœ‹Serverèµ„æºä½¿ç”¨**:
```bash
docker stats tunnox-server-1 tunnox-server-2 tunnox-server-3
```

**æŸ¥çœ‹Redisæ€§èƒ½**:
```bash
docker exec -it redis redis-cli INFO stats
docker exec -it redis redis-cli SLOWLOG GET 10
```

---

## ğŸ“‹ æµ‹è¯•æ£€æŸ¥æ¸…å•

### é˜¶æ®µ6.1 ä»»åŠ¡æ¸…å•

- [ ] ç¼–å†™Docker Composeé…ç½®ï¼ˆ3èŠ‚ç‚¹+Nginx+Redisï¼‰
- [ ] ç¼–å†™Nginxè´Ÿè½½å‡è¡¡é…ç½®ï¼ˆ4ç§ç­–ç•¥ï¼‰
- [ ] å®ç° `TestLoadBalancer_ControlAndTunnelSeparation`
- [ ] å®ç° `TestLoadBalancer_CrossServerMessaging`
- [ ] å®ç° `TestLoadBalancer_NodeFailover`
- [ ] å®ç° `TestLoadBalancer_DifferentStrategies`
- [ ] å®ç° `TestLoadBalancer_HighConcurrency`
- [ ] å®ç° `TestLoadBalancer_DynamicScaling`
- [ ] ç¼–å†™æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬
- [ ] éªŒè¯æ‰€æœ‰æµ‹è¯•é€šè¿‡

### éªŒæ”¶æ ‡å‡†

- âœ… æ‰€æœ‰è´Ÿè½½å‡è¡¡æµ‹è¯•ç”¨ä¾‹é€šè¿‡
- âœ… æ§åˆ¶è¿æ¥å’Œéš§é“è¿æ¥åˆ†ç¦»åœºæ™¯æ­£å¸¸å·¥ä½œ
- âœ… è·¨Serveræ¶ˆæ¯ä¼ é€’å»¶è¿Ÿ < 100ms
- âœ… èŠ‚ç‚¹æ•…éšœè½¬ç§»æ—¶é—´ < 10s
- âœ… é«˜å¹¶å‘æˆåŠŸç‡ > 95%
- âœ… åŠ¨æ€æ‰©ç¼©å®¹æ— æ•°æ®ä¸¢å¤±
- âœ… æ€§èƒ½æŒ‡æ ‡è¾¾åˆ°é¢„æœŸ

---

## ğŸ¯ æ€»ç»“

è´Ÿè½½å‡è¡¡åœºæ™¯æ˜¯åˆ†å¸ƒå¼éƒ¨ç½²çš„æ ¸å¿ƒæŒ‘æˆ˜ï¼Œéœ€è¦é‡ç‚¹æµ‹è¯•ï¼š

1. **è·¨Serverè·¯ç”±** - å‘½ä»¤é€šé“å’Œéš§é“è¿æ¥å¯èƒ½åœ¨ä¸åŒServer
2. **é…ç½®åŒæ­¥** - é€šè¿‡Redis+MQä¿è¯é…ç½®ä¸€è‡´æ€§
3. **æ•…éšœè½¬ç§»** - èŠ‚ç‚¹æ•…éšœæ—¶å®¢æˆ·ç«¯è‡ªåŠ¨é‡è¿
4. **è´Ÿè½½å‡è¡¡ç­–ç•¥** - ä¸åŒç­–ç•¥çš„é€‚ç”¨åœºæ™¯
5. **åŠ¨æ€æ‰©ç¼©å®¹** - æ— ç¼æ·»åŠ /ç§»é™¤Server
6. **æ€§èƒ½å‹åŠ›** - é«˜å¹¶å‘ä¸‹çš„ç¨³å®šæ€§

è¿™äº›æµ‹è¯•ç¡®ä¿Tunnoxåœ¨ç”Ÿäº§ç¯å¢ƒçš„å¤šèŠ‚ç‚¹éƒ¨ç½²ä¸‹èƒ½å¤Ÿç¨³å®šã€é«˜æ•ˆåœ°å·¥ä½œï¼

